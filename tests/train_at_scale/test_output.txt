[1m============================= test session starts ==============================[0m
platform darwin -- Python 3.10.6, pytest-7.4.3, pluggy-1.3.0 -- /Users/reecepalmer/.pyenv/versions/3.10.6/envs/taxifare-env/bin/python3.10
cachedir: .pytest_cache
rootdir: /Users/reecepalmer/Code/RPalmr/07-ML-Ops/01-Train-at-scale/data-train-at-scale/tests
configfile: pytest_kitt.ini
[1mcollecting ... [0mcollected 8 items

tests/train_at_scale/test_clean.py::test_clean_data [32mPASSED[0m[32m               [ 12%][0m
tests/train_at_scale/test_main_local.py::TestMainLocal::test_route_preprocess_and_train [31mFAILED[0m[31m [ 25%][0m
tests/train_at_scale/test_main_local.py::TestMainLocal::test_route_pred [31mFAILED[0m[31m [ 37%][0m
tests/train_at_scale/test_main_local.py::TestMainLocal::test_route_preprocess [31mFAILED[0m[31m [ 50%][0m
tests/train_at_scale/test_main_local.py::TestMainLocal::test_route_train [31mFAILED[0m[31m [ 62%][0m
tests/train_at_scale/test_model.py::test_model_can_fit [31mFAILED[0m[31m            [ 75%][0m
tests/train_at_scale/test_notebook.py::TestNotebook::test_y_pred [32mPASSED[0m[31m  [ 87%][0m
tests/train_at_scale/test_processor_pipeline.py::test_preprocess_features [32mPASSED[0m[31m [100%][0m

=================================== FAILURES ===================================
[31m[1m________________ TestMainLocal.test_route_preprocess_and_train _________________[0m

self = <tests.train_at_scale.test_main_local.TestMainLocal object at 0x1318bb5e0>

    [94mdef[39;49;00m [92mtest_route_preprocess_and_train[39;49;00m([96mself[39;49;00m):[90m[39;49;00m
    [90m[39;49;00m
        [90m# 1) SETUP[39;49;00m[90m[39;49;00m
        data_query_path = Path(LOCAL_DATA_PATH).joinpath([33m"[39;49;00m[33mraw[39;49;00m[33m"[39;49;00m,[33mf[39;49;00m[33m"[39;49;00m[33mquery_[39;49;00m[33m{[39;49;00mMIN_DATE[33m}[39;49;00m[33m_[39;49;00m[33m{[39;49;00mMAX_DATE[33m}[39;49;00m[33m_[39;49;00m[33m{[39;49;00mDATA_SIZE[33m}[39;49;00m[33m.csv[39;49;00m[33m"[39;49;00m)[90m[39;49;00m
        data_query_exists = data_query_path.is_file()[90m[39;49;00m
    [90m[39;49;00m
        [94mif[39;49;00m data_query_exists:[90m[39;49;00m
            [90m# We start from a blank state. No cached files[39;49;00m[90m[39;49;00m
            shutil.copyfile(data_query_path, [33mf[39;49;00m[33m'[39;49;00m[33m{[39;49;00mdata_query_path[33m}[39;49;00m[33m_backup[39;49;00m[33m'[39;49;00m)[90m[39;49;00m
            data_query_path.unlink()[90m[39;49;00m
    [90m[39;49;00m
        [90m# 2) ACT[39;49;00m[90m[39;49;00m
        [94mfrom[39;49;00m [04m[96mtaxifare[39;49;00m[04m[96m.[39;49;00m[04m[96minterface[39;49;00m[04m[96m.[39;49;00m[04m[96mmain_local[39;49;00m [94mimport[39;49;00m preprocess_and_train[90m[39;49;00m
    [90m[39;49;00m
        [90m# Check route runs correctly[39;49;00m[90m[39;49;00m
>       preprocess_and_train(min_date=MIN_DATE, max_date=MAX_DATE)[90m[39;49;00m

[1m[31mtests/train_at_scale/test_main_local.py[0m:36: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

min_date = '2009-01-01', max_date = '2015-01-01'

    [94mdef[39;49;00m [92mpreprocess_and_train[39;49;00m(min_date:[96mstr[39;49;00m = [33m'[39;49;00m[33m2009-01-01[39;49;00m[33m'[39;49;00m, max_date:[96mstr[39;49;00m = [33m'[39;49;00m[33m2015-01-01[39;49;00m[33m'[39;49;00m) -> [94mNone[39;49;00m:[90m[39;49;00m
    [90m    [39;49;00m[33m"""[39;49;00m
    [33m    - Query the raw dataset from Le Wagon's BigQuery dataset[39;49;00m
    [33m    - Cache query result as a local CSV if it doesn't exist locally[39;49;00m
    [33m    - Clean and preprocess data[39;49;00m
    [33m    - Train a Keras model on it[39;49;00m
    [33m    - Save the model[39;49;00m
    [33m    - Compute & save a validation performance metric[39;49;00m
    [33m    """[39;49;00m[90m[39;49;00m
    [90m[39;49;00m
        [96mprint[39;49;00m(Fore.MAGENTA + [33m"[39;49;00m[33m\n[39;49;00m[33m ‚≠êÔ∏è Use case: preprocess_and_train[39;49;00m[33m"[39;49;00m + Style.RESET_ALL)[90m[39;49;00m
    [90m[39;49;00m
        min_date = parse(min_date).strftime([33m'[39;49;00m[33m%[39;49;00m[33mY-[39;49;00m[33m%[39;49;00m[33mm-[39;49;00m[33m%d[39;49;00m[33m'[39;49;00m) [90m# e.g '2009-01-01'[39;49;00m[90m[39;49;00m
        max_date = parse(max_date).strftime([33m'[39;49;00m[33m%[39;49;00m[33mY-[39;49;00m[33m%[39;49;00m[33mm-[39;49;00m[33m%d[39;49;00m[33m'[39;49;00m) [90m# e.g '2009-01-01'[39;49;00m[90m[39;49;00m
    [90m[39;49;00m
        query = [33mf[39;49;00m[33m"""[39;49;00m[33m[39;49;00m
    [33m        SELECT [39;49;00m[33m{[39;49;00m[33m"[39;49;00m[33m,[39;49;00m[33m"[39;49;00m.join(COLUMN_NAMES_RAW)[33m}[39;49;00m[33m[39;49;00m
    [33m        FROM [39;49;00m[33m{[39;49;00mGCP_PROJECT_WAGON[33m}[39;49;00m[33m.[39;49;00m[33m{[39;49;00mBQ_DATASET[33m}[39;49;00m[33m.raw_[39;49;00m[33m{[39;49;00mDATA_SIZE[33m}[39;49;00m[33m[39;49;00m
    [33m        WHERE pickup_datetime BETWEEN [39;49;00m[33m'[39;49;00m[33m{[39;49;00mmin_date[33m}[39;49;00m[33m'[39;49;00m[33m AND [39;49;00m[33m'[39;49;00m[33m{[39;49;00mmax_date[33m}[39;49;00m[33m'[39;49;00m[33m[39;49;00m
    [33m        ORDER BY pickup_datetime[39;49;00m[33m[39;49;00m
    [33m        [39;49;00m[33m"""[39;49;00m[90m[39;49;00m
    [90m[39;49;00m
        [90m# Retrieve `query` data from BigQuery or from `data_query_cache_path` if the file already exists![39;49;00m[90m[39;49;00m
        data_query_cache_path = Path(LOCAL_DATA_PATH).joinpath([33m"[39;49;00m[33mraw[39;49;00m[33m"[39;49;00m, [33mf[39;49;00m[33m"[39;49;00m[33mquery_[39;49;00m[33m{[39;49;00mmin_date[33m}[39;49;00m[33m_[39;49;00m[33m{[39;49;00mmax_date[33m}[39;49;00m[33m_[39;49;00m[33m{[39;49;00mDATA_SIZE[33m}[39;49;00m[33m.csv[39;49;00m[33m"[39;49;00m)[90m[39;49;00m
        data_query_cached_exists = data_query_cache_path.is_file()[90m[39;49;00m
    [90m[39;49;00m
        [94mif[39;49;00m data_query_cached_exists:[90m[39;49;00m
            [96mprint[39;49;00m([33m"[39;49;00m[33mLoading data from local CSV...[39;49;00m[33m"[39;49;00m)[90m[39;49;00m
    [90m[39;49;00m
            [90m# YOUR CODE HERE[39;49;00m[90m[39;49;00m
    [90m[39;49;00m
        [94melse[39;49;00m:[90m[39;49;00m
            [96mprint[39;49;00m([33m"[39;49;00m[33mLoading data from Querying Big Query server...[39;49;00m[33m"[39;49;00m)[90m[39;49;00m
    [90m[39;49;00m
            [90m# YOUR CODE HERE[39;49;00m[90m[39;49;00m
    [90m[39;49;00m
            [90m# Save it locally to accelerate the next queries![39;49;00m[90m[39;49;00m
>           data.to_csv(data_query_cache_path, header=[94mTrue[39;49;00m, index=[94mFalse[39;49;00m)[90m[39;49;00m
[1m[31mE           NameError: name 'data' is not defined[0m

[1m[31mtaxifare/interface/main_local.py[0m:52: NameError
----------------------------- Captured stdout call -----------------------------
[34m
Loading TensorFlow...[0m

‚úÖ TensorFlow loaded (0.0s)
[35m
 ‚≠êÔ∏è Use case: preprocess_and_train[0m
Loading data from Querying Big Query server...
[31m[1m________________________ TestMainLocal.test_route_pred _________________________[0m

self = <tests.train_at_scale.test_main_local.TestMainLocal object at 0x1318bb6a0>

    [94mdef[39;49;00m [92mtest_route_pred[39;49;00m([96mself[39;49;00m):[90m[39;49;00m
        [94mfrom[39;49;00m [04m[96mtaxifare[39;49;00m[04m[96m.[39;49;00m[04m[96minterface[39;49;00m[04m[96m.[39;49;00m[04m[96mmain_local[39;49;00m [94mimport[39;49;00m pred[90m[39;49;00m
    [90m[39;49;00m
>       y_pred = pred()[90m[39;49;00m

[1m[31mtests/train_at_scale/test_main_local.py[0m:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X_pred =             pickup_datetime  ...  passenger_count
0 2013-07-06 17:18:00+00:00  ...                1

[1 rows x 6 columns]

    [94mdef[39;49;00m [92mpred[39;49;00m(X_pred: pd.DataFrame = [94mNone[39;49;00m) -> np.ndarray:[90m[39;49;00m
        [96mprint[39;49;00m(Fore.MAGENTA + [33m"[39;49;00m[33m\n[39;49;00m[33m ‚≠êÔ∏è Use case: pred[39;49;00m[33m"[39;49;00m + Style.RESET_ALL)[90m[39;49;00m
    [90m[39;49;00m
        [94mif[39;49;00m X_pred [95mis[39;49;00m [94mNone[39;49;00m:[90m[39;49;00m
            X_pred = pd.DataFrame([96mdict[39;49;00m([90m[39;49;00m
                pickup_datetime=[pd.Timestamp([33m"[39;49;00m[33m2013-07-06 17:18:00[39;49;00m[33m"[39;49;00m, tz=[33m'[39;49;00m[33mUTC[39;49;00m[33m'[39;49;00m)],[90m[39;49;00m
                pickup_longitude=[-[94m73.950655[39;49;00m],[90m[39;49;00m
                pickup_latitude=[[94m40.783282[39;49;00m],[90m[39;49;00m
                dropoff_longitude=[-[94m73.984365[39;49;00m],[90m[39;49;00m
                dropoff_latitude=[[94m40.769802[39;49;00m],[90m[39;49;00m
                passenger_count=[[94m1[39;49;00m],[90m[39;49;00m
            ))[90m[39;49;00m
    [90m[39;49;00m
        model = load_model()[90m[39;49;00m
        X_processed = preprocess_features(X_pred)[90m[39;49;00m
>       y_pred = model.predict(X_processed)[90m[39;49;00m
[1m[31mE       AttributeError: 'NoneType' object has no attribute 'predict'[0m

[1m[31mtaxifare/interface/main_local.py[0m:106: AttributeError
----------------------------- Captured stdout call -----------------------------
[35m
 ‚≠êÔ∏è Use case: pred[0m
[34m
Load latest model from local registry...[0m
[34m
Preprocessing features...[0m
‚úÖ X_processed, with shape (1, 65)
[31m[1m_____________________ TestMainLocal.test_route_preprocess ______________________[0m

self = <tests.train_at_scale.test_main_local.TestMainLocal object at 0x1318bb880>
fixture_query_1k =      fare_amount           pickup_datetime  ...  dropoff_latitude  passenger_count
0            8.9 2009-01-15 09:22:3...           4
454          8.5 2014-12-27 16:47:42+00:00  ...         40.771263                4

[455 rows x 7 columns]
fixture_processed_1k =            0    1    2    3    4    5   ...   60   61   62   63   64         65
0    0.000000  0.0  0.0  0.0  1.0  0.0...0.0   6.500000
446  0.428571  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   8.500000

[447 rows x 66 columns]

    [94mdef[39;49;00m [92mtest_route_preprocess[39;49;00m([96mself[39;49;00m, fixture_query_1k: pd.DataFrame, fixture_processed_1k: pd.DataFrame):[90m[39;49;00m
>       [94mfrom[39;49;00m [04m[96mtaxifare[39;49;00m[04m[96m.[39;49;00m[04m[96minterface[39;49;00m[04m[96m.[39;49;00m[04m[96mmain_local[39;49;00m [94mimport[39;49;00m preprocess[90m[39;49;00m
[1m[31mE       ImportError: cannot import name 'preprocess' from 'taxifare.interface.main_local' (/Users/reecepalmer/Code/RPalmr/07-ML-Ops/01-Train-at-scale/data-train-at-scale/taxifare/interface/main_local.py)[0m

[1m[31mtests/train_at_scale/test_main_local.py[0m:67: ImportError
[31m[1m________________________ TestMainLocal.test_route_train ________________________[0m

self = <tests.train_at_scale.test_main_local.TestMainLocal object at 0x1318bb7c0>

    [94mdef[39;49;00m [92mtest_route_train[39;49;00m([96mself[39;49;00m):[90m[39;49;00m
    [90m[39;49;00m
        [90m# SETUP[39;49;00m[90m[39;49;00m
        data_processed_path = Path(LOCAL_DATA_PATH).joinpath([33m"[39;49;00m[33mprocessed[39;49;00m[33m"[39;49;00m,[33mf[39;49;00m[33m"[39;49;00m[33mprocessed_[39;49;00m[33m{[39;49;00mMIN_DATE[33m}[39;49;00m[33m_[39;49;00m[33m{[39;49;00mMAX_DATE[33m}[39;49;00m[33m_[39;49;00m[33m{[39;49;00mDATA_SIZE[33m}[39;49;00m[33m.csv[39;49;00m[33m"[39;49;00m)[90m[39;49;00m
        data_processed_exists = data_processed_path.is_file()[90m[39;49;00m
        [94mif[39;49;00m data_processed_exists:[90m[39;49;00m
            shutil.copyfile(data_processed_path, [33mf[39;49;00m[33m'[39;49;00m[33m{[39;49;00mdata_processed_path[33m}[39;49;00m[33m_backup[39;49;00m[33m'[39;49;00m)[90m[39;49;00m
            data_processed_path.unlink()[90m[39;49;00m
    [90m[39;49;00m
        data_processed_fixture_path = [33m"[39;49;00m[33mhttps://storage.googleapis.com/datascience-mlops/taxi-fare-ny/solutions/data_processed_fixture_2009-01-01_2015-01-01_1k.csv[39;49;00m[33m"[39;49;00m[90m[39;49;00m
        os.system([33mf[39;49;00m[33m"[39;49;00m[33mcurl [39;49;00m[33m{[39;49;00mdata_processed_fixture_path[33m}[39;49;00m[33m > [39;49;00m[33m{[39;49;00mdata_processed_path[33m}[39;49;00m[33m"[39;49;00m)[90m[39;49;00m
    [90m[39;49;00m
        [90m# ACT[39;49;00m[90m[39;49;00m
>       [94mfrom[39;49;00m [04m[96mtaxifare[39;49;00m[04m[96m.[39;49;00m[04m[96minterface[39;49;00m[04m[96m.[39;49;00m[04m[96mmain_local[39;49;00m [94mimport[39;49;00m train[90m[39;49;00m
[1m[31mE       ImportError: cannot import name 'train' from 'taxifare.interface.main_local' (/Users/reecepalmer/Code/RPalmr/07-ML-Ops/01-Train-at-scale/data-train-at-scale/taxifare/interface/main_local.py)[0m

[1m[31mtests/train_at_scale/test_main_local.py[0m:126: ImportError
----------------------------- Captured stderr call -----------------------------
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100  153k  100  153k    0     0  1408k      0 --:--:-- --:--:-- --:--:-- 1480k
[31m[1m______________________________ test_model_can_fit ______________________________[0m

fixture_processed_1k =            0    1    2    3    4    5   ...   60   61   62   63   64         65
0    0.000000  0.0  0.0  0.0  1.0  0.0...0.0   6.500000
446  0.428571  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   8.500000

[447 rows x 66 columns]

    [94mdef[39;49;00m [92mtest_model_can_fit[39;49;00m(fixture_processed_1k):[90m[39;49;00m
    [90m[39;49;00m
        [94mfrom[39;49;00m [04m[96mtaxifare[39;49;00m[04m[96m.[39;49;00m[04m[96mml_logic[39;49;00m[04m[96m.[39;49;00m[04m[96mmodel[39;49;00m [94mimport[39;49;00m initialize_model,compile_model, train_model[90m[39;49;00m
        fixture_X_processed = fixture_processed_1k.to_numpy()[:,:-[94m1[39;49;00m][90m[39;49;00m
        fixture_y = fixture_processed_1k.to_numpy()[:,-[94m1[39;49;00m][90m[39;49;00m
        model = initialize_model(fixture_X_processed.shape[[94m1[39;49;00m:])[90m[39;49;00m
        model = compile_model(model, learning_rate=[94m0.001[39;49;00m)[90m[39;49;00m
>       model, history = train_model(model=model,[90m[39;49;00m
                                     X=fixture_X_processed,[90m[39;49;00m
                                     y=fixture_y,[90m[39;49;00m
                                     validation_split=[94m0.3[39;49;00m)[90m[39;49;00m

[1m[31mtests/train_at_scale/test_model.py[0m:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

model = <keras.engine.sequential.Sequential object at 0x281861360>
X = array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,
        0.        ],
       [0.        , 0.  ...       ],
       [0.42857143, 0.        , 0.        , ..., 0.        , 0.        ,
        0.        ]], dtype=float32)
y = array([ 8.9 ,  4.1 , 10.6 ,  8.3 , 38.2 ,  8.9 , 12.9 ,  4.9 ,  6.3 ,
        3.3 ,  7.7 ,  9.7 , 10.9 ,  7.3 , 12.6 ,...9.5 , 11.  ,  6.5 , 13.5 , 10.5 ,  7.5 ,  8.  , 26.5 ,
       20.  , 12.5 , 52.5 ,  7.5 ,  6.5 ,  8.5 ], dtype=float32)
batch_size = 256, patience = 2, validation_data = None, validation_split = 0.3

    [94mdef[39;49;00m [92mtrain_model[39;49;00m([90m[39;49;00m
            model: Model,[90m[39;49;00m
            X: np.ndarray,[90m[39;49;00m
            y: np.ndarray,[90m[39;49;00m
            batch_size=[94m256[39;49;00m,[90m[39;49;00m
            patience=[94m2[39;49;00m,[90m[39;49;00m
            validation_data=[94mNone[39;49;00m,  [90m# overrides validation_split[39;49;00m[90m[39;49;00m
            validation_split=[94m0.3[39;49;00m[90m[39;49;00m
    ) -> Tuple[Model, [96mdict[39;49;00m]:[90m[39;49;00m
    [90m    [39;49;00m[33m"""[39;49;00m
    [33m    Fit the model and return a tuple (fitted_model, history)[39;49;00m
    [33m    """[39;49;00m[90m[39;49;00m
        es = EarlyStopping([90m[39;49;00m
        monitor=[33m"[39;49;00m[33mval_loss[39;49;00m[33m"[39;49;00m,[90m[39;49;00m
        patience=[94m2[39;49;00m,[90m[39;49;00m
        restore_best_weights=[94mTrue[39;49;00m,[90m[39;49;00m
        verbose=[94m0[39;49;00m[90m[39;49;00m
    )[90m[39;49;00m
    [90m[39;49;00m
        history = model.fit([90m[39;49;00m
            X,[90m[39;49;00m
            y,[90m[39;49;00m
            validation_data=(validation_data),[90m[39;49;00m
            epochs=[94m100[39;49;00m,[90m[39;49;00m
            batch_size=batch_size,[90m[39;49;00m
            callbacks=[es],[90m[39;49;00m
            verbose=[94m1[39;49;00m[90m[39;49;00m
        )[90m[39;49;00m
    [90m[39;49;00m
>       [96mprint[39;49;00m([33mf[39;49;00m[33m"[39;49;00m[33m‚úÖ Model trained on [39;49;00m[33m{[39;49;00m[96mlen[39;49;00m(X)[33m}[39;49;00m[33m rows with min val MAE: [39;49;00m[33m{[39;49;00m[96mround[39;49;00m(np.min(history.history[[33m'[39;49;00m[33mval_mae[39;49;00m[33m'[39;49;00m]),[90m [39;49;00m[94m2[39;49;00m)[33m}[39;49;00m[33m"[39;49;00m)[90m[39;49;00m
[1m[31mE       KeyError: 'val_mae'[0m

[1m[31mtaxifare/ml_logic/model.py[0m:82: KeyError
----------------------------- Captured stdout call -----------------------------
‚úÖ Model initialized
‚úÖ Model compiled
Epoch 1/100
1/2 [==============>...............] - ETA: 0s - loss: 175.4094 - mae: 10.33502/2 [==============================] - 0s 2ms/step - loss: 194.7777 - mae: 10.7327
Epoch 2/100
1/2 [==============>...............] - ETA: 0s - loss: 209.2637 - mae: 11.01342/2 [==============================] - 0s 1ms/step - loss: 191.5952 - mae: 10.7008
Epoch 3/100
1/2 [==============>...............] - ETA: 0s - loss: 195.9330 - mae: 10.89332/2 [==============================] - 0s 1ms/step - loss: 191.0942 - mae: 10.7352
Epoch 4/100
1/2 [==============>...............] - ETA: 0s - loss: 203.0921 - mae: 11.25152/2 [==============================] - 0s 1ms/step - loss: 187.0399 - mae: 10.6903
Epoch 5/100
1/2 [==============>...............] - ETA: 0s - loss: 214.5962 - mae: 11.00072/2 [==============================] - 0s 1ms/step - loss: 186.1257 - mae: 10.6670
Epoch 6/100
1/2 [==============>...............] - ETA: 0s - loss: 178.9323 - mae: 10.48022/2 [==============================] - 0s 1ms/step - loss: 183.0657 - mae: 10.6598
Epoch 7/100
1/2 [==============>...............] - ETA: 0s - loss: 181.1352 - mae: 10.41872/2 [==============================] - 0s 1ms/step - loss: 179.3509 - mae: 10.5995
Epoch 8/100
1/2 [==============>...............] - ETA: 0s - loss: 157.8402 - mae: 10.15942/2 [==============================] - 0s 1ms/step - loss: 177.2955 - mae: 10.5676
Epoch 9/100
1/2 [==============>...............] - ETA: 0s - loss: 164.2974 - mae: 10.37852/2 [==============================] - 0s 1ms/step - loss: 177.0697 - mae: 10.6018
Epoch 10/100
1/2 [==============>...............] - ETA: 0s - loss: 175.1077 - mae: 10.47992/2 [==============================] - 0s 966us/step - loss: 173.7122 - mae: 10.5447
Epoch 11/100
1/2 [==============>...............] - ETA: 0s - loss: 176.9044 - mae: 10.67692/2 [==============================] - 0s 1ms/step - loss: 171.9838 - mae: 10.5257
Epoch 12/100
1/2 [==============>...............] - ETA: 0s - loss: 180.4835 - mae: 10.84382/2 [==============================] - 0s 1ms/step - loss: 171.5164 - mae: 10.5331
Epoch 13/100
1/2 [==============>...............] - ETA: 0s - loss: 169.2984 - mae: 10.54742/2 [==============================] - 0s 2ms/step - loss: 169.0682 - mae: 10.5446
Epoch 14/100
1/2 [==============>...............] - ETA: 0s - loss: 163.4813 - mae: 10.50062/2 [==============================] - 0s 1ms/step - loss: 166.5524 - mae: 10.4955
Epoch 15/100
1/2 [==============>...............] - ETA: 0s - loss: 182.8812 - mae: 10.74082/2 [==============================] - 0s 1ms/step - loss: 164.0900 - mae: 10.4321
Epoch 16/100
1/2 [==============>...............] - ETA: 0s - loss: 139.5627 - mae: 9.76932/2 [==============================] - 0s 1ms/step - loss: 162.6337 - mae: 10.4429
Epoch 17/100
1/2 [==============>...............] - ETA: 0s - loss: 166.0231 - mae: 10.26362/2 [==============================] - 0s 1ms/step - loss: 160.5631 - mae: 10.4231
Epoch 18/100
1/2 [==============>...............] - ETA: 0s - loss: 176.8918 - mae: 10.72102/2 [==============================] - 0s 1ms/step - loss: 159.7874 - mae: 10.4124
Epoch 19/100
1/2 [==============>...............] - ETA: 0s - loss: 145.4803 - mae: 9.96512/2 [==============================] - 0s 1ms/step - loss: 156.0961 - mae: 10.3492
Epoch 20/100
1/2 [==============>...............] - ETA: 0s - loss: 167.4870 - mae: 10.58972/2 [==============================] - 0s 1ms/step - loss: 153.6879 - mae: 10.3200
Epoch 21/100
1/2 [==============>...............] - ETA: 0s - loss: 137.1419 - mae: 9.84812/2 [==============================] - 0s 1ms/step - loss: 152.2505 - mae: 10.3122
Epoch 22/100
1/2 [==============>...............] - ETA: 0s - loss: 146.7108 - mae: 10.16432/2 [==============================] - 0s 1ms/step - loss: 150.5820 - mae: 10.2685
Epoch 23/100
1/2 [==============>...............] - ETA: 0s - loss: 149.3739 - mae: 10.23052/2 [==============================] - 0s 1ms/step - loss: 146.9390 - mae: 10.2658
Epoch 24/100
1/2 [==============>...............] - ETA: 0s - loss: 135.8488 - mae: 9.96352/2 [==============================] - 0s 1ms/step - loss: 145.2317 - mae: 10.2254
Epoch 25/100
1/2 [==============>...............] - ETA: 0s - loss: 131.4885 - mae: 9.98142/2 [==============================] - 0s 982us/step - loss: 143.8046 - mae: 10.1985
Epoch 26/100
1/2 [==============>...............] - ETA: 0s - loss: 148.0517 - mae: 10.37802/2 [==============================] - 0s 1ms/step - loss: 143.0612 - mae: 10.2169
Epoch 27/100
1/2 [==============>...............] - ETA: 0s - loss: 123.6977 - mae: 9.69732/2 [==============================] - 0s 999us/step - loss: 140.6976 - mae: 10.1786
Epoch 28/100
1/2 [==============>...............] - ETA: 0s - loss: 145.9697 - mae: 10.33522/2 [==============================] - 0s 1ms/step - loss: 137.0843 - mae: 10.0855
Epoch 29/100
1/2 [==============>...............] - ETA: 0s - loss: 149.6262 - mae: 10.52262/2 [==============================] - 0s 1ms/step - loss: 135.4563 - mae: 10.0870
Epoch 30/100
1/2 [==============>...............] - ETA: 0s - loss: 143.6802 - mae: 10.32402/2 [==============================] - 0s 993us/step - loss: 133.1062 - mae: 10.0195
Epoch 31/100
1/2 [==============>...............] - ETA: 0s - loss: 142.5295 - mae: 10.23702/2 [==============================] - 0s 1ms/step - loss: 131.4928 - mae: 10.0333
Epoch 32/100
1/2 [==============>...............] - ETA: 0s - loss: 125.9412 - mae: 9.89982/2 [==============================] - 0s 1ms/step - loss: 129.1685 - mae: 10.0150
Epoch 33/100
1/2 [==============>...............] - ETA: 0s - loss: 117.7418 - mae: 9.57912/2 [==============================] - 0s 1ms/step - loss: 128.7549 - mae: 9.9760
Epoch 34/100
1/2 [==============>...............] - ETA: 0s - loss: 128.1772 - mae: 10.03042/2 [==============================] - 0s 1ms/step - loss: 124.6874 - mae: 9.8917
Epoch 35/100
1/2 [==============>...............] - ETA: 0s - loss: 124.3302 - mae: 9.97012/2 [==============================] - 0s 993us/step - loss: 122.9674 - mae: 9.8959
Epoch 36/100
1/2 [==============>...............] - ETA: 0s - loss: 127.2940 - mae: 10.10042/2 [==============================] - 0s 1ms/step - loss: 121.4308 - mae: 9.8295
Epoch 37/100
1/2 [==============>...............] - ETA: 0s - loss: 121.4023 - mae: 9.87282/2 [==============================] - 0s 1ms/step - loss: 119.2834 - mae: 9.8464
Epoch 38/100
1/2 [==============>...............] - ETA: 0s - loss: 99.4146 - mae: 9.06382/2 [==============================] - 0s 1ms/step - loss: 120.3743 - mae: 9.8165
Epoch 39/100
1/2 [==============>...............] - ETA: 0s - loss: 131.7876 - mae: 10.37042/2 [==============================] - 0s 1ms/step - loss: 115.5646 - mae: 9.7343
Epoch 40/100
1/2 [==============>...............] - ETA: 0s - loss: 129.3248 - mae: 10.18972/2 [==============================] - 0s 1ms/step - loss: 113.4611 - mae: 9.6545
Epoch 41/100
1/2 [==============>...............] - ETA: 0s - loss: 121.1004 - mae: 10.01392/2 [==============================] - 0s 1ms/step - loss: 112.4122 - mae: 9.6395
Epoch 42/100
1/2 [==============>...............] - ETA: 0s - loss: 103.9660 - mae: 9.29142/2 [==============================] - 0s 1ms/step - loss: 112.2042 - mae: 9.6255
Epoch 43/100
1/2 [==============>...............] - ETA: 0s - loss: 118.4148 - mae: 9.81462/2 [==============================] - 0s 1ms/step - loss: 110.2675 - mae: 9.5542
Epoch 44/100
1/2 [==============>...............] - ETA: 0s - loss: 110.8618 - mae: 9.70982/2 [==============================] - 0s 1ms/step - loss: 107.6527 - mae: 9.5252
Epoch 45/100
1/2 [==============>...............] - ETA: 0s - loss: 115.6462 - mae: 9.75372/2 [==============================] - 0s 1ms/step - loss: 108.5197 - mae: 9.5332
Epoch 46/100
1/2 [==============>...............] - ETA: 0s - loss: 97.6837 - mae: 9.21072/2 [==============================] - 0s 1ms/step - loss: 105.6365 - mae: 9.4529
Epoch 47/100
1/2 [==============>...............] - ETA: 0s - loss: 98.8681 - mae: 9.22352/2 [==============================] - 0s 1ms/step - loss: 106.0184 - mae: 9.4856
Epoch 48/100
1/2 [==============>...............] - ETA: 0s - loss: 85.7310 - mae: 8.64442/2 [==============================] - 0s 1ms/step - loss: 103.8467 - mae: 9.4062
Epoch 49/100
1/2 [==============>...............] - ETA: 0s - loss: 107.5520 - mae: 9.61232/2 [==============================] - 0s 1ms/step - loss: 102.0070 - mae: 9.3575
Epoch 50/100
1/2 [==============>...............] - ETA: 0s - loss: 106.7131 - mae: 9.57592/2 [==============================] - 0s 1ms/step - loss: 99.4147 - mae: 9.2549
Epoch 51/100
1/2 [==============>...............] - ETA: 0s - loss: 104.4673 - mae: 9.59502/2 [==============================] - 0s 1ms/step - loss: 98.9676 - mae: 9.2498
Epoch 52/100
1/2 [==============>...............] - ETA: 0s - loss: 103.0116 - mae: 9.37052/2 [==============================] - 0s 1ms/step - loss: 98.6846 - mae: 9.2277
Epoch 53/100
1/2 [==============>...............] - ETA: 0s - loss: 88.3508 - mae: 8.79372/2 [==============================] - 0s 1ms/step - loss: 95.7617 - mae: 9.1465
Epoch 54/100
1/2 [==============>...............] - ETA: 0s - loss: 86.0208 - mae: 8.64992/2 [==============================] - 0s 1ms/step - loss: 95.6332 - mae: 9.1405
Epoch 55/100
1/2 [==============>...............] - ETA: 0s - loss: 91.3091 - mae: 8.94962/2 [==============================] - 0s 1ms/step - loss: 94.0625 - mae: 9.0642
Epoch 56/100
1/2 [==============>...............] - ETA: 0s - loss: 75.9525 - mae: 8.18202/2 [==============================] - 0s 1ms/step - loss: 95.1926 - mae: 9.0490
Epoch 57/100
1/2 [==============>...............] - ETA: 0s - loss: 89.4020 - mae: 8.81342/2 [==============================] - 0s 1ms/step - loss: 92.7117 - mae: 9.0112
Epoch 58/100
1/2 [==============>...............] - ETA: 0s - loss: 100.2480 - mae: 9.33772/2 [==============================] - 0s 1ms/step - loss: 91.8922 - mae: 8.9647
Epoch 59/100
1/2 [==============>...............] - ETA: 0s - loss: 89.0770 - mae: 8.84982/2 [==============================] - 0s 1ms/step - loss: 89.2700 - mae: 8.8996
Epoch 60/100
1/2 [==============>...............] - ETA: 0s - loss: 95.8632 - mae: 9.28492/2 [==============================] - 0s 1ms/step - loss: 88.2648 - mae: 8.8476
Epoch 61/100
1/2 [==============>...............] - ETA: 0s - loss: 83.7915 - mae: 8.58632/2 [==============================] - 0s 1ms/step - loss: 86.9632 - mae: 8.7884
Epoch 62/100
1/2 [==============>...............] - ETA: 0s - loss: 85.2122 - mae: 8.68592/2 [==============================] - 0s 1ms/step - loss: 85.6286 - mae: 8.7395
Epoch 63/100
1/2 [==============>...............] - ETA: 0s - loss: 85.3361 - mae: 8.68532/2 [==============================] - 0s 1ms/step - loss: 86.2430 - mae: 8.7331
Epoch 64/100
1/2 [==============>...............] - ETA: 0s - loss: 73.9244 - mae: 8.01192/2 [==============================] - 0s 1ms/step - loss: 85.5437 - mae: 8.6683
Epoch 65/100
1/2 [==============>...............] - ETA: 0s - loss: 79.8524 - mae: 8.42362/2 [==============================] - 0s 1ms/step - loss: 83.5749 - mae: 8.6283
Epoch 66/100
1/2 [==============>...............] - ETA: 0s - loss: 91.3779 - mae: 9.02212/2 [==============================] - 0s 1ms/step - loss: 84.3642 - mae: 8.6208
Epoch 67/100
1/2 [==============>...............] - ETA: 0s - loss: 85.1514 - mae: 8.67842/2 [==============================] - 0s 1ms/step - loss: 81.4235 - mae: 8.4809
Epoch 68/100
1/2 [==============>...............] - ETA: 0s - loss: 90.0284 - mae: 8.97052/2 [==============================] - 0s 1ms/step - loss: 82.5879 - mae: 8.5735
Epoch 69/100
1/2 [==============>...............] - ETA: 0s - loss: 81.6534 - mae: 8.52942/2 [==============================] - 0s 1ms/step - loss: 79.0442 - mae: 8.3938
Epoch 70/100
1/2 [==============>...............] - ETA: 0s - loss: 79.6380 - mae: 8.48592/2 [==============================] - 0s 1ms/step - loss: 78.5389 - mae: 8.3363
Epoch 71/100
1/2 [==============>...............] - ETA: 0s - loss: 70.5756 - mae: 7.86122/2 [==============================] - 0s 1ms/step - loss: 78.7074 - mae: 8.3428
Epoch 72/100
1/2 [==============>...............] - ETA: 0s - loss: 76.3821 - mae: 8.21312/2 [==============================] - 0s 1ms/step - loss: 78.4504 - mae: 8.3381
Epoch 73/100
1/2 [==============>...............] - ETA: 0s - loss: 71.9103 - mae: 8.00002/2 [==============================] - 0s 1ms/step - loss: 77.3699 - mae: 8.2645
Epoch 74/100
1/2 [==============>...............] - ETA: 0s - loss: 80.9764 - mae: 8.50252/2 [==============================] - 0s 1ms/step - loss: 76.9907 - mae: 8.2406
Epoch 75/100
1/2 [==============>...............] - ETA: 0s - loss: 64.7662 - mae: 7.54122/2 [==============================] - 0s 1ms/step - loss: 74.7876 - mae: 8.1292
Epoch 76/100
1/2 [==============>...............] - ETA: 0s - loss: 79.8760 - mae: 8.48372/2 [==============================] - 0s 1ms/step - loss: 74.1706 - mae: 8.0776
Epoch 77/100
1/2 [==============>...............] - ETA: 0s - loss: 66.1196 - mae: 7.60892/2 [==============================] - 0s 1ms/step - loss: 73.1320 - mae: 8.0343
Epoch 78/100
1/2 [==============>...............] - ETA: 0s - loss: 63.2038 - mae: 7.47692/2 [==============================] - 0s 1ms/step - loss: 72.8462 - mae: 7.9772
Epoch 79/100
1/2 [==============>...............] - ETA: 0s - loss: 60.4254 - mae: 7.21952/2 [==============================] - 0s 1ms/step - loss: 71.9940 - mae: 7.9149
Epoch 80/100
1/2 [==============>...............] - ETA: 0s - loss: 61.3921 - mae: 7.32162/2 [==============================] - 0s 1ms/step - loss: 71.7222 - mae: 7.9263
Epoch 81/100
1/2 [==============>...............] - ETA: 0s - loss: 66.2812 - mae: 7.65442/2 [==============================] - 0s 1ms/step - loss: 71.3461 - mae: 7.9239
Epoch 82/100
1/2 [==============>...............] - ETA: 0s - loss: 67.3761 - mae: 7.74502/2 [==============================] - 0s 1ms/step - loss: 68.0805 - mae: 7.7518
Epoch 83/100
1/2 [==============>...............] - ETA: 0s - loss: 68.3478 - mae: 7.77692/2 [==============================] - 0s 1ms/step - loss: 67.4935 - mae: 7.7400
Epoch 84/100
1/2 [==============>...............] - ETA: 0s - loss: 69.5230 - mae: 7.82762/2 [==============================] - 0s 1ms/step - loss: 65.8856 - mae: 7.6213
Epoch 85/100
1/2 [==============>...............] - ETA: 0s - loss: 73.9434 - mae: 8.02672/2 [==============================] - 0s 1ms/step - loss: 66.8115 - mae: 7.6118
Epoch 86/100
1/2 [==============>...............] - ETA: 0s - loss: 65.5236 - mae: 7.63912/2 [==============================] - 0s 1ms/step - loss: 64.0510 - mae: 7.5217
Epoch 87/100
1/2 [==============>...............] - ETA: 0s - loss: 64.5468 - mae: 7.57482/2 [==============================] - 0s 1ms/step - loss: 63.2504 - mae: 7.4764
Epoch 88/100
1/2 [==============>...............] - ETA: 0s - loss: 65.5349 - mae: 7.58702/2 [==============================] - 0s 1ms/step - loss: 63.2102 - mae: 7.4338
Epoch 89/100
1/2 [==============>...............] - ETA: 0s - loss: 60.5144 - mae: 7.27082/2 [==============================] - 0s 1ms/step - loss: 62.0876 - mae: 7.3909
Epoch 90/100
1/2 [==============>...............] - ETA: 0s - loss: 59.1274 - mae: 7.15692/2 [==============================] - 0s 1ms/step - loss: 62.1787 - mae: 7.3650
Epoch 91/100
1/2 [==============>...............] - ETA: 0s - loss: 54.2498 - mae: 6.87072/2 [==============================] - 0s 1ms/step - loss: 59.7429 - mae: 7.2409
Epoch 92/100
1/2 [==============>...............] - ETA: 0s - loss: 60.5356 - mae: 7.26472/2 [==============================] - 0s 1ms/step - loss: 59.7111 - mae: 7.2354
Epoch 93/100
1/2 [==============>...............] - ETA: 0s - loss: 58.2091 - mae: 7.17202/2 [==============================] - 0s 1ms/step - loss: 58.5942 - mae: 7.1857
Epoch 94/100
1/2 [==============>...............] - ETA: 0s - loss: 56.1532 - mae: 7.00892/2 [==============================] - 0s 1ms/step - loss: 58.4026 - mae: 7.1233
Epoch 95/100
1/2 [==============>...............] - ETA: 0s - loss: 52.7875 - mae: 6.77082/2 [==============================] - 0s 1ms/step - loss: 57.9584 - mae: 7.1458
Epoch 96/100
1/2 [==============>...............] - ETA: 0s - loss: 62.7043 - mae: 7.39702/2 [==============================] - 0s 1ms/step - loss: 56.0079 - mae: 6.9437
Epoch 97/100
1/2 [==============>...............] - ETA: 0s - loss: 53.1207 - mae: 6.79482/2 [==============================] - 0s 1ms/step - loss: 54.1640 - mae: 6.8668
Epoch 98/100
1/2 [==============>...............] - ETA: 0s - loss: 58.1325 - mae: 7.11752/2 [==============================] - 0s 1ms/step - loss: 55.2149 - mae: 6.9092
Epoch 99/100
1/2 [==============>...............] - ETA: 0s - loss: 50.1802 - mae: 6.53502/2 [==============================] - 0s 1ms/step - loss: 54.3292 - mae: 6.8073
Epoch 100/100
1/2 [==============>...............] - ETA: 0s - loss: 56.4161 - mae: 6.99762/2 [==============================] - 0s 1ms/step - loss: 53.4771 - mae: 6.7921
----------------------------- Captured stderr call -----------------------------
2023-11-27 14:32:25.989222: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz
------------------------------ Captured log call -------------------------------
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[36m[1m=========================== short test summary info ============================[0m
[31mFAILED[0m tests/train_at_scale/test_main_local.py::[1mTestMainLocal::test_route_preprocess_and_train[0m - NameError: name 'data' is not defined
[31mFAILED[0m tests/train_at_scale/test_main_local.py::[1mTestMainLocal::test_route_pred[0m - AttributeError: 'NoneType' object has no attribute 'predict'
[31mFAILED[0m tests/train_at_scale/test_main_local.py::[1mTestMainLocal::test_route_preprocess[0m - ImportError: cannot import name 'preprocess' from 'taxifare.interface.main_...
[31mFAILED[0m tests/train_at_scale/test_main_local.py::[1mTestMainLocal::test_route_train[0m - ImportError: cannot import name 'train' from 'taxifare.interface.main_local...
[31mFAILED[0m tests/train_at_scale/test_model.py::[1mtest_model_can_fit[0m - KeyError: 'val_mae'
[31m================== [31m[1m5 failed[0m, [32m3 passed[0m, [33m103 warnings[0m[31m in 6.11s[0m[31m ===================[0m
