[1m============================= test session starts ==============================[0m
platform darwin -- Python 3.10.6, pytest-7.4.3, pluggy-1.3.0 -- /Users/reecepalmer/.pyenv/versions/3.10.6/envs/taxifare-env/bin/python3.10
cachedir: .pytest_cache
rootdir: /Users/reecepalmer/Code/RPalmr/07-ML-Ops/01-Train-at-scale/data-train-at-scale/tests
configfile: pytest_kitt.ini
[1mcollecting ... [0mcollected 8 items

tests/train_at_scale/test_clean.py::test_clean_data [32mPASSED[0m[32m               [ 12%][0m
tests/train_at_scale/test_main_local.py::TestMainLocal::test_route_preprocess_and_train [31mFAILED[0m[31m [ 25%][0m
tests/train_at_scale/test_main_local.py::TestMainLocal::test_route_pred [31mFAILED[0m[31m [ 37%][0m
tests/train_at_scale/test_main_local.py::TestMainLocal::test_route_preprocess [31mFAILED[0m[31m [ 50%][0m
tests/train_at_scale/test_main_local.py::TestMainLocal::test_route_train [31mFAILED[0m[31m [ 62%][0m
tests/train_at_scale/test_model.py::test_model_can_fit [31mFAILED[0m[31m            [ 75%][0m
tests/train_at_scale/test_notebook.py::TestNotebook::test_y_pred [32mPASSED[0m[31m  [ 87%][0m
tests/train_at_scale/test_processor_pipeline.py::test_preprocess_features [32mPASSED[0m[31m [100%][0m

=================================== FAILURES ===================================
[31m[1m________________ TestMainLocal.test_route_preprocess_and_train _________________[0m

self = <tests.train_at_scale.test_main_local.TestMainLocal object at 0x13e30b700>

    [94mdef[39;49;00m [92mtest_route_preprocess_and_train[39;49;00m([96mself[39;49;00m):[90m[39;49;00m
    [90m[39;49;00m
        [90m# 1) SETUP[39;49;00m[90m[39;49;00m
        data_query_path = Path(LOCAL_DATA_PATH).joinpath([33m"[39;49;00m[33mraw[39;49;00m[33m"[39;49;00m,[33mf[39;49;00m[33m"[39;49;00m[33mquery_[39;49;00m[33m{[39;49;00mMIN_DATE[33m}[39;49;00m[33m_[39;49;00m[33m{[39;49;00mMAX_DATE[33m}[39;49;00m[33m_[39;49;00m[33m{[39;49;00mDATA_SIZE[33m}[39;49;00m[33m.csv[39;49;00m[33m"[39;49;00m)[90m[39;49;00m
        data_query_exists = data_query_path.is_file()[90m[39;49;00m
    [90m[39;49;00m
        [94mif[39;49;00m data_query_exists:[90m[39;49;00m
            [90m# We start from a blank state. No cached files[39;49;00m[90m[39;49;00m
            shutil.copyfile(data_query_path, [33mf[39;49;00m[33m'[39;49;00m[33m{[39;49;00mdata_query_path[33m}[39;49;00m[33m_backup[39;49;00m[33m'[39;49;00m)[90m[39;49;00m
            data_query_path.unlink()[90m[39;49;00m
    [90m[39;49;00m
        [90m# 2) ACT[39;49;00m[90m[39;49;00m
        [94mfrom[39;49;00m [04m[96mtaxifare[39;49;00m[04m[96m.[39;49;00m[04m[96minterface[39;49;00m[04m[96m.[39;49;00m[04m[96mmain_local[39;49;00m [94mimport[39;49;00m preprocess_and_train[90m[39;49;00m
    [90m[39;49;00m
        [90m# Check route runs correctly[39;49;00m[90m[39;49;00m
>       preprocess_and_train(min_date=MIN_DATE, max_date=MAX_DATE)[90m[39;49;00m

[1m[31mtests/train_at_scale/test_main_local.py[0m:36: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

min_date = '2009-01-01', max_date = '2015-01-01'

    [94mdef[39;49;00m [92mpreprocess_and_train[39;49;00m(min_date:[96mstr[39;49;00m = [33m'[39;49;00m[33m2009-01-01[39;49;00m[33m'[39;49;00m, max_date:[96mstr[39;49;00m = [33m'[39;49;00m[33m2015-01-01[39;49;00m[33m'[39;49;00m) -> [94mNone[39;49;00m:[90m[39;49;00m
    [90m    [39;49;00m[33m"""[39;49;00m
    [33m    - Query the raw dataset from Le Wagon's BigQuery dataset[39;49;00m
    [33m    - Cache query result as a local CSV if it doesn't exist locally[39;49;00m
    [33m    - Clean and preprocess data[39;49;00m
    [33m    - Train a Keras model on it[39;49;00m
    [33m    - Save the model[39;49;00m
    [33m    - Compute & save a validation performance metric[39;49;00m
    [33m    """[39;49;00m[90m[39;49;00m
    [90m[39;49;00m
        [96mprint[39;49;00m(Fore.MAGENTA + [33m"[39;49;00m[33m\n[39;49;00m[33m ‚≠êÔ∏è Use case: preprocess_and_train[39;49;00m[33m"[39;49;00m + Style.RESET_ALL)[90m[39;49;00m
    [90m[39;49;00m
        min_date = parse(min_date).strftime([33m'[39;49;00m[33m%[39;49;00m[33mY-[39;49;00m[33m%[39;49;00m[33mm-[39;49;00m[33m%d[39;49;00m[33m'[39;49;00m) [90m# e.g '2009-01-01'[39;49;00m[90m[39;49;00m
        max_date = parse(max_date).strftime([33m'[39;49;00m[33m%[39;49;00m[33mY-[39;49;00m[33m%[39;49;00m[33mm-[39;49;00m[33m%d[39;49;00m[33m'[39;49;00m) [90m# e.g '2009-01-01'[39;49;00m[90m[39;49;00m
    [90m[39;49;00m
        query = [33mf[39;49;00m[33m"""[39;49;00m[33m[39;49;00m
    [33m        SELECT [39;49;00m[33m{[39;49;00m[33m"[39;49;00m[33m,[39;49;00m[33m"[39;49;00m.join(COLUMN_NAMES_RAW)[33m}[39;49;00m[33m[39;49;00m
    [33m        FROM [39;49;00m[33m{[39;49;00mGCP_PROJECT_WAGON[33m}[39;49;00m[33m.[39;49;00m[33m{[39;49;00mBQ_DATASET[33m}[39;49;00m[33m.raw_[39;49;00m[33m{[39;49;00mDATA_SIZE[33m}[39;49;00m[33m[39;49;00m
    [33m        WHERE pickup_datetime BETWEEN [39;49;00m[33m'[39;49;00m[33m{[39;49;00mmin_date[33m}[39;49;00m[33m'[39;49;00m[33m AND [39;49;00m[33m'[39;49;00m[33m{[39;49;00mmax_date[33m}[39;49;00m[33m'[39;49;00m[33m[39;49;00m
    [33m        ORDER BY pickup_datetime[39;49;00m[33m[39;49;00m
    [33m        [39;49;00m[33m"""[39;49;00m[90m[39;49;00m
    [90m[39;49;00m
        [90m# Retrieve `query` data from BigQuery or from `data_query_cache_path` if the file already exists![39;49;00m[90m[39;49;00m
        data_query_cache_path = Path(LOCAL_DATA_PATH).joinpath([33m"[39;49;00m[33mraw[39;49;00m[33m"[39;49;00m, [33mf[39;49;00m[33m"[39;49;00m[33mquery_[39;49;00m[33m{[39;49;00mmin_date[33m}[39;49;00m[33m_[39;49;00m[33m{[39;49;00mmax_date[33m}[39;49;00m[33m_[39;49;00m[33m{[39;49;00mDATA_SIZE[33m}[39;49;00m[33m.csv[39;49;00m[33m"[39;49;00m)[90m[39;49;00m
        data_query_cached_exists = data_query_cache_path.is_file()[90m[39;49;00m
    [90m[39;49;00m
        [94mif[39;49;00m data_query_cached_exists:[90m[39;49;00m
            [96mprint[39;49;00m([33m"[39;49;00m[33mLoading data from local CSV...[39;49;00m[33m"[39;49;00m)[90m[39;49;00m
    [90m[39;49;00m
            [90m# YOUR CODE HERE[39;49;00m[90m[39;49;00m
    [90m[39;49;00m
        [94melse[39;49;00m:[90m[39;49;00m
            [96mprint[39;49;00m([33m"[39;49;00m[33mLoading data from Querying Big Query server...[39;49;00m[33m"[39;49;00m)[90m[39;49;00m
    [90m[39;49;00m
            [90m# YOUR CODE HERE[39;49;00m[90m[39;49;00m
    [90m[39;49;00m
            [90m# Save it locally to accelerate the next queries![39;49;00m[90m[39;49;00m
>           data.to_csv(data_query_cache_path, header=[94mTrue[39;49;00m, index=[94mFalse[39;49;00m)[90m[39;49;00m
[1m[31mE           NameError: name 'data' is not defined[0m

[1m[31mtaxifare/interface/main_local.py[0m:52: NameError
----------------------------- Captured stdout call -----------------------------
[34m
Loading TensorFlow...[0m

‚úÖ TensorFlow loaded (0.0s)
[35m
 ‚≠êÔ∏è Use case: preprocess_and_train[0m
Loading data from Querying Big Query server...
[31m[1m________________________ TestMainLocal.test_route_pred _________________________[0m

self = <tests.train_at_scale.test_main_local.TestMainLocal object at 0x13e30b7c0>

    [94mdef[39;49;00m [92mtest_route_pred[39;49;00m([96mself[39;49;00m):[90m[39;49;00m
        [94mfrom[39;49;00m [04m[96mtaxifare[39;49;00m[04m[96m.[39;49;00m[04m[96minterface[39;49;00m[04m[96m.[39;49;00m[04m[96mmain_local[39;49;00m [94mimport[39;49;00m pred[90m[39;49;00m
    [90m[39;49;00m
>       y_pred = pred()[90m[39;49;00m

[1m[31mtests/train_at_scale/test_main_local.py[0m:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X_pred =             pickup_datetime  ...  passenger_count
0 2013-07-06 17:18:00+00:00  ...                1

[1 rows x 6 columns]

    [94mdef[39;49;00m [92mpred[39;49;00m(X_pred: pd.DataFrame = [94mNone[39;49;00m) -> np.ndarray:[90m[39;49;00m
        [96mprint[39;49;00m(Fore.MAGENTA + [33m"[39;49;00m[33m\n[39;49;00m[33m ‚≠êÔ∏è Use case: pred[39;49;00m[33m"[39;49;00m + Style.RESET_ALL)[90m[39;49;00m
    [90m[39;49;00m
        [94mif[39;49;00m X_pred [95mis[39;49;00m [94mNone[39;49;00m:[90m[39;49;00m
            X_pred = pd.DataFrame([96mdict[39;49;00m([90m[39;49;00m
                pickup_datetime=[pd.Timestamp([33m"[39;49;00m[33m2013-07-06 17:18:00[39;49;00m[33m"[39;49;00m, tz=[33m'[39;49;00m[33mUTC[39;49;00m[33m'[39;49;00m)],[90m[39;49;00m
                pickup_longitude=[-[94m73.950655[39;49;00m],[90m[39;49;00m
                pickup_latitude=[[94m40.783282[39;49;00m],[90m[39;49;00m
                dropoff_longitude=[-[94m73.984365[39;49;00m],[90m[39;49;00m
                dropoff_latitude=[[94m40.769802[39;49;00m],[90m[39;49;00m
                passenger_count=[[94m1[39;49;00m],[90m[39;49;00m
            ))[90m[39;49;00m
    [90m[39;49;00m
        model = load_model()[90m[39;49;00m
        X_processed = preprocess_features(X_pred)[90m[39;49;00m
>       y_pred = model.predict(X_processed)[90m[39;49;00m
[1m[31mE       AttributeError: 'NoneType' object has no attribute 'predict'[0m

[1m[31mtaxifare/interface/main_local.py[0m:106: AttributeError
----------------------------- Captured stdout call -----------------------------
[35m
 ‚≠êÔ∏è Use case: pred[0m
[34m
Load latest model from local registry...[0m
[34m
Preprocessing features...[0m
‚úÖ X_processed, with shape (1, 65)
[31m[1m_____________________ TestMainLocal.test_route_preprocess ______________________[0m

self = <tests.train_at_scale.test_main_local.TestMainLocal object at 0x13e30b9a0>
fixture_query_1k =      fare_amount           pickup_datetime  ...  dropoff_latitude  passenger_count
0            8.9 2009-01-15 09:22:3...           4
454          8.5 2014-12-27 16:47:42+00:00  ...         40.771263                4

[455 rows x 7 columns]
fixture_processed_1k =            0    1    2    3    4    5   ...   60   61   62   63   64         65
0    0.000000  0.0  0.0  0.0  1.0  0.0...0.0   6.500000
446  0.428571  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   8.500000

[447 rows x 66 columns]

    [94mdef[39;49;00m [92mtest_route_preprocess[39;49;00m([96mself[39;49;00m, fixture_query_1k: pd.DataFrame, fixture_processed_1k: pd.DataFrame):[90m[39;49;00m
>       [94mfrom[39;49;00m [04m[96mtaxifare[39;49;00m[04m[96m.[39;49;00m[04m[96minterface[39;49;00m[04m[96m.[39;49;00m[04m[96mmain_local[39;49;00m [94mimport[39;49;00m preprocess[90m[39;49;00m
[1m[31mE       ImportError: cannot import name 'preprocess' from 'taxifare.interface.main_local' (/Users/reecepalmer/Code/RPalmr/07-ML-Ops/01-Train-at-scale/data-train-at-scale/taxifare/interface/main_local.py)[0m

[1m[31mtests/train_at_scale/test_main_local.py[0m:67: ImportError
[31m[1m________________________ TestMainLocal.test_route_train ________________________[0m

self = <tests.train_at_scale.test_main_local.TestMainLocal object at 0x13e30b8e0>

    [94mdef[39;49;00m [92mtest_route_train[39;49;00m([96mself[39;49;00m):[90m[39;49;00m
    [90m[39;49;00m
        [90m# SETUP[39;49;00m[90m[39;49;00m
        data_processed_path = Path(LOCAL_DATA_PATH).joinpath([33m"[39;49;00m[33mprocessed[39;49;00m[33m"[39;49;00m,[33mf[39;49;00m[33m"[39;49;00m[33mprocessed_[39;49;00m[33m{[39;49;00mMIN_DATE[33m}[39;49;00m[33m_[39;49;00m[33m{[39;49;00mMAX_DATE[33m}[39;49;00m[33m_[39;49;00m[33m{[39;49;00mDATA_SIZE[33m}[39;49;00m[33m.csv[39;49;00m[33m"[39;49;00m)[90m[39;49;00m
        data_processed_exists = data_processed_path.is_file()[90m[39;49;00m
        [94mif[39;49;00m data_processed_exists:[90m[39;49;00m
            shutil.copyfile(data_processed_path, [33mf[39;49;00m[33m'[39;49;00m[33m{[39;49;00mdata_processed_path[33m}[39;49;00m[33m_backup[39;49;00m[33m'[39;49;00m)[90m[39;49;00m
            data_processed_path.unlink()[90m[39;49;00m
    [90m[39;49;00m
        data_processed_fixture_path = [33m"[39;49;00m[33mhttps://storage.googleapis.com/datascience-mlops/taxi-fare-ny/solutions/data_processed_fixture_2009-01-01_2015-01-01_1k.csv[39;49;00m[33m"[39;49;00m[90m[39;49;00m
        os.system([33mf[39;49;00m[33m"[39;49;00m[33mcurl [39;49;00m[33m{[39;49;00mdata_processed_fixture_path[33m}[39;49;00m[33m > [39;49;00m[33m{[39;49;00mdata_processed_path[33m}[39;49;00m[33m"[39;49;00m)[90m[39;49;00m
    [90m[39;49;00m
        [90m# ACT[39;49;00m[90m[39;49;00m
>       [94mfrom[39;49;00m [04m[96mtaxifare[39;49;00m[04m[96m.[39;49;00m[04m[96minterface[39;49;00m[04m[96m.[39;49;00m[04m[96mmain_local[39;49;00m [94mimport[39;49;00m train[90m[39;49;00m
[1m[31mE       ImportError: cannot import name 'train' from 'taxifare.interface.main_local' (/Users/reecepalmer/Code/RPalmr/07-ML-Ops/01-Train-at-scale/data-train-at-scale/taxifare/interface/main_local.py)[0m

[1m[31mtests/train_at_scale/test_main_local.py[0m:126: ImportError
----------------------------- Captured stderr call -----------------------------
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100  153k  100  153k    0     0  1935k      0 --:--:-- --:--:-- --:--:-- 2025k
[31m[1m______________________________ test_model_can_fit ______________________________[0m

fixture_processed_1k =            0    1    2    3    4    5   ...   60   61   62   63   64         65
0    0.000000  0.0  0.0  0.0  1.0  0.0...0.0   6.500000
446  0.428571  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   8.500000

[447 rows x 66 columns]

    [94mdef[39;49;00m [92mtest_model_can_fit[39;49;00m(fixture_processed_1k):[90m[39;49;00m
    [90m[39;49;00m
        [94mfrom[39;49;00m [04m[96mtaxifare[39;49;00m[04m[96m.[39;49;00m[04m[96mml_logic[39;49;00m[04m[96m.[39;49;00m[04m[96mmodel[39;49;00m [94mimport[39;49;00m initialize_model,compile_model, train_model[90m[39;49;00m
        fixture_X_processed = fixture_processed_1k.to_numpy()[:,:-[94m1[39;49;00m][90m[39;49;00m
        fixture_y = fixture_processed_1k.to_numpy()[:,-[94m1[39;49;00m][90m[39;49;00m
        model = initialize_model(fixture_X_processed.shape[[94m1[39;49;00m:])[90m[39;49;00m
        model = compile_model(model, learning_rate=[94m0.001[39;49;00m)[90m[39;49;00m
>       model, history = train_model(model=model,[90m[39;49;00m
                                     X=fixture_X_processed,[90m[39;49;00m
                                     y=fixture_y,[90m[39;49;00m
                                     validation_split=[94m0.3[39;49;00m)[90m[39;49;00m

[1m[31mtests/train_at_scale/test_model.py[0m:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

model = <keras.engine.sequential.Sequential object at 0x2897a0550>
X = array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,
        0.        ],
       [0.        , 0.  ...       ],
       [0.42857143, 0.        , 0.        , ..., 0.        , 0.        ,
        0.        ]], dtype=float32)
y = array([ 8.9 ,  4.1 , 10.6 ,  8.3 , 38.2 ,  8.9 , 12.9 ,  4.9 ,  6.3 ,
        3.3 ,  7.7 ,  9.7 , 10.9 ,  7.3 , 12.6 ,...9.5 , 11.  ,  6.5 , 13.5 , 10.5 ,  7.5 ,  8.  , 26.5 ,
       20.  , 12.5 , 52.5 ,  7.5 ,  6.5 ,  8.5 ], dtype=float32)
batch_size = 256, patience = 2, validation_data = None, validation_split = 0.3

    [94mdef[39;49;00m [92mtrain_model[39;49;00m([90m[39;49;00m
            model: Model,[90m[39;49;00m
            X: np.ndarray,[90m[39;49;00m
            y: np.ndarray,[90m[39;49;00m
            batch_size=[94m256[39;49;00m,[90m[39;49;00m
            patience=[94m2[39;49;00m,[90m[39;49;00m
            validation_data=[94mNone[39;49;00m,  [90m# overrides validation_split[39;49;00m[90m[39;49;00m
            validation_split=[94m0.3[39;49;00m[90m[39;49;00m
    ) -> Tuple[Model, [96mdict[39;49;00m]:[90m[39;49;00m
    [90m    [39;49;00m[33m"""[39;49;00m
    [33m    Fit the model and return a tuple (fitted_model, history)[39;49;00m
    [33m    """[39;49;00m[90m[39;49;00m
        es = EarlyStopping([90m[39;49;00m
        monitor=[33m"[39;49;00m[33mval_loss[39;49;00m[33m"[39;49;00m,[90m[39;49;00m
        patience=[94m2[39;49;00m,[90m[39;49;00m
        restore_best_weights=[94mTrue[39;49;00m,[90m[39;49;00m
        verbose=[94m0[39;49;00m[90m[39;49;00m
    )[90m[39;49;00m
    [90m[39;49;00m
        history = model.fit([90m[39;49;00m
            X,[90m[39;49;00m
            y,[90m[39;49;00m
            validation_data=(validation_data),[90m[39;49;00m
            epochs=[94m100[39;49;00m,[90m[39;49;00m
            batch_size=batch_size,[90m[39;49;00m
            callbacks=[es],[90m[39;49;00m
            verbose=[94m1[39;49;00m[90m[39;49;00m
        )[90m[39;49;00m
    [90m[39;49;00m
>       [96mprint[39;49;00m([33mf[39;49;00m[33m"[39;49;00m[33m‚úÖ Model trained on [39;49;00m[33m{[39;49;00m[96mlen[39;49;00m(X)[33m}[39;49;00m[33m rows with min val MAE: [39;49;00m[33m{[39;49;00m[96mround[39;49;00m(np.min(history.history[[33m'[39;49;00m[33mval_mae[39;49;00m[33m'[39;49;00m]),[90m [39;49;00m[94m2[39;49;00m)[33m}[39;49;00m[33m"[39;49;00m)[90m[39;49;00m
[1m[31mE       KeyError: 'val_mae'[0m

[1m[31mtaxifare/ml_logic/model.py[0m:82: KeyError
----------------------------- Captured stdout call -----------------------------
‚úÖ Model initialized
‚úÖ Model compiled
Epoch 1/100
1/2 [==============>...............] - ETA: 0s - loss: 200.9779 - mae: 10.71392/2 [==============================] - 0s 2ms/step - loss: 196.5648 - mae: 10.6980
Epoch 2/100
1/2 [==============>...............] - ETA: 0s - loss: 174.1149 - mae: 10.04382/2 [==============================] - 0s 2ms/step - loss: 193.9138 - mae: 10.7168
Epoch 3/100
1/2 [==============>...............] - ETA: 0s - loss: 201.1218 - mae: 11.00292/2 [==============================] - 0s 1ms/step - loss: 192.0629 - mae: 10.7179
Epoch 4/100
1/2 [==============>...............] - ETA: 0s - loss: 192.4196 - mae: 10.75012/2 [==============================] - 0s 1ms/step - loss: 188.5110 - mae: 10.6829
Epoch 5/100
1/2 [==============>...............] - ETA: 0s - loss: 175.2802 - mae: 10.38712/2 [==============================] - 0s 1ms/step - loss: 185.6200 - mae: 10.6811
Epoch 6/100
1/2 [==============>...............] - ETA: 0s - loss: 184.4111 - mae: 10.52872/2 [==============================] - 0s 1ms/step - loss: 185.2945 - mae: 10.6745
Epoch 7/100
1/2 [==============>...............] - ETA: 0s - loss: 160.1780 - mae: 9.94472/2 [==============================] - 0s 1ms/step - loss: 181.4287 - mae: 10.6268
Epoch 8/100
1/2 [==============>...............] - ETA: 0s - loss: 183.5179 - mae: 10.68522/2 [==============================] - 0s 1ms/step - loss: 179.9530 - mae: 10.6156
Epoch 9/100
1/2 [==============>...............] - ETA: 0s - loss: 179.4595 - mae: 10.72952/2 [==============================] - 0s 2ms/step - loss: 177.0131 - mae: 10.6083
Epoch 10/100
1/2 [==============>...............] - ETA: 0s - loss: 178.5101 - mae: 10.63192/2 [==============================] - 0s 1ms/step - loss: 174.5175 - mae: 10.5538
Epoch 11/100
1/2 [==============>...............] - ETA: 0s - loss: 203.0280 - mae: 11.21702/2 [==============================] - 0s 2ms/step - loss: 173.6374 - mae: 10.5798
Epoch 12/100
1/2 [==============>...............] - ETA: 0s - loss: 167.6853 - mae: 10.37262/2 [==============================] - 0s 1ms/step - loss: 171.3841 - mae: 10.5147
Epoch 13/100
1/2 [==============>...............] - ETA: 0s - loss: 153.4876 - mae: 10.08132/2 [==============================] - 0s 1ms/step - loss: 169.4741 - mae: 10.5057
Epoch 14/100
1/2 [==============>...............] - ETA: 0s - loss: 156.2058 - mae: 10.19272/2 [==============================] - 0s 975us/step - loss: 168.1218 - mae: 10.5142
Epoch 15/100
1/2 [==============>...............] - ETA: 0s - loss: 164.0782 - mae: 10.26692/2 [==============================] - 0s 1ms/step - loss: 166.2348 - mae: 10.4822
Epoch 16/100
1/2 [==============>...............] - ETA: 0s - loss: 154.9834 - mae: 10.27652/2 [==============================] - 0s 1ms/step - loss: 163.7837 - mae: 10.4422
Epoch 17/100
1/2 [==============>...............] - ETA: 0s - loss: 177.0007 - mae: 10.85482/2 [==============================] - 0s 1ms/step - loss: 161.7070 - mae: 10.3919
Epoch 18/100
1/2 [==============>...............] - ETA: 0s - loss: 147.0421 - mae: 10.05542/2 [==============================] - 0s 1ms/step - loss: 158.8456 - mae: 10.3752
Epoch 19/100
1/2 [==============>...............] - ETA: 0s - loss: 164.8791 - mae: 10.50342/2 [==============================] - 0s 1ms/step - loss: 158.7918 - mae: 10.4006
Epoch 20/100
1/2 [==============>...............] - ETA: 0s - loss: 166.9058 - mae: 10.58182/2 [==============================] - 0s 1ms/step - loss: 157.0643 - mae: 10.3503
Epoch 21/100
1/2 [==============>...............] - ETA: 0s - loss: 149.7828 - mae: 10.23872/2 [==============================] - 0s 1ms/step - loss: 153.0515 - mae: 10.3209
Epoch 22/100
1/2 [==============>...............] - ETA: 0s - loss: 139.0806 - mae: 9.94582/2 [==============================] - 0s 1ms/step - loss: 150.5208 - mae: 10.2795
Epoch 23/100
1/2 [==============>...............] - ETA: 0s - loss: 168.8336 - mae: 10.58222/2 [==============================] - 0s 1ms/step - loss: 151.8263 - mae: 10.2896
Epoch 24/100
1/2 [==============>...............] - ETA: 0s - loss: 137.8169 - mae: 9.81392/2 [==============================] - 0s 1ms/step - loss: 151.9444 - mae: 10.3296
Epoch 25/100
1/2 [==============>...............] - ETA: 0s - loss: 156.3773 - mae: 10.44102/2 [==============================] - 0s 2ms/step - loss: 145.2230 - mae: 10.2109
Epoch 26/100
1/2 [==============>...............] - ETA: 0s - loss: 152.9423 - mae: 10.32482/2 [==============================] - 0s 1ms/step - loss: 142.9978 - mae: 10.1904
Epoch 27/100
1/2 [==============>...............] - ETA: 0s - loss: 137.1451 - mae: 10.05742/2 [==============================] - 0s 1ms/step - loss: 142.7701 - mae: 10.1748
Epoch 28/100
1/2 [==============>...............] - ETA: 0s - loss: 130.7652 - mae: 9.69812/2 [==============================] - 0s 1ms/step - loss: 141.9794 - mae: 10.1777
Epoch 29/100
1/2 [==============>...............] - ETA: 0s - loss: 137.8883 - mae: 10.00012/2 [==============================] - 0s 2ms/step - loss: 139.6872 - mae: 10.1644
Epoch 30/100
1/2 [==============>...............] - ETA: 0s - loss: 150.9847 - mae: 10.48702/2 [==============================] - 0s 2ms/step - loss: 137.9722 - mae: 10.1426
Epoch 31/100
1/2 [==============>...............] - ETA: 0s - loss: 133.9345 - mae: 10.11682/2 [==============================] - 0s 1ms/step - loss: 134.0029 - mae: 10.0228
Epoch 32/100
1/2 [==============>...............] - ETA: 0s - loss: 127.3058 - mae: 9.95172/2 [==============================] - 0s 1ms/step - loss: 132.5772 - mae: 10.0333
Epoch 33/100
1/2 [==============>...............] - ETA: 0s - loss: 139.6947 - mae: 10.14592/2 [==============================] - 0s 1ms/step - loss: 128.8186 - mae: 9.9065
Epoch 34/100
1/2 [==============>...............] - ETA: 0s - loss: 125.0804 - mae: 9.97662/2 [==============================] - 0s 1ms/step - loss: 128.7028 - mae: 9.9851
Epoch 35/100
1/2 [==============>...............] - ETA: 0s - loss: 106.5634 - mae: 9.35862/2 [==============================] - 0s 1ms/step - loss: 127.5204 - mae: 9.9159
Epoch 36/100
1/2 [==============>...............] - ETA: 0s - loss: 125.0374 - mae: 10.03552/2 [==============================] - 0s 1ms/step - loss: 125.7053 - mae: 9.9129
Epoch 37/100
1/2 [==============>...............] - ETA: 0s - loss: 124.3339 - mae: 9.92832/2 [==============================] - 0s 1ms/step - loss: 122.6607 - mae: 9.8568
Epoch 38/100
1/2 [==============>...............] - ETA: 0s - loss: 130.2573 - mae: 10.23522/2 [==============================] - 0s 2ms/step - loss: 122.0426 - mae: 9.8583
Epoch 39/100
1/2 [==============>...............] - ETA: 0s - loss: 128.9251 - mae: 10.19152/2 [==============================] - 0s 2ms/step - loss: 120.2081 - mae: 9.8048
Epoch 40/100
1/2 [==============>...............] - ETA: 0s - loss: 118.7719 - mae: 9.70202/2 [==============================] - 0s 1ms/step - loss: 117.6296 - mae: 9.7206
Epoch 41/100
1/2 [==============>...............] - ETA: 0s - loss: 116.3322 - mae: 9.73162/2 [==============================] - 0s 2ms/step - loss: 117.3890 - mae: 9.7284
Epoch 42/100
1/2 [==============>...............] - ETA: 0s - loss: 119.7519 - mae: 9.76442/2 [==============================] - 0s 1ms/step - loss: 115.6685 - mae: 9.6811
Epoch 43/100
1/2 [==============>...............] - ETA: 0s - loss: 110.5293 - mae: 9.38732/2 [==============================] - 0s 1ms/step - loss: 111.7319 - mae: 9.5691
Epoch 44/100
1/2 [==============>...............] - ETA: 0s - loss: 93.5301 - mae: 8.78412/2 [==============================] - 0s 2ms/step - loss: 112.3964 - mae: 9.5737
Epoch 45/100
1/2 [==============>...............] - ETA: 0s - loss: 130.0605 - mae: 10.37302/2 [==============================] - 0s 2ms/step - loss: 112.2554 - mae: 9.6272
Epoch 46/100
1/2 [==============>...............] - ETA: 0s - loss: 118.2248 - mae: 9.84752/2 [==============================] - 0s 1ms/step - loss: 108.5835 - mae: 9.4956
Epoch 47/100
1/2 [==============>...............] - ETA: 0s - loss: 103.9826 - mae: 9.32322/2 [==============================] - 0s 1ms/step - loss: 108.1246 - mae: 9.4910
Epoch 48/100
1/2 [==============>...............] - ETA: 0s - loss: 90.5545 - mae: 8.83712/2 [==============================] - 0s 2ms/step - loss: 104.7371 - mae: 9.3374
Epoch 49/100
1/2 [==============>...............] - ETA: 0s - loss: 102.7430 - mae: 9.39902/2 [==============================] - 0s 1ms/step - loss: 103.0912 - mae: 9.3447
Epoch 50/100
1/2 [==============>...............] - ETA: 0s - loss: 101.4651 - mae: 9.33952/2 [==============================] - 0s 1ms/step - loss: 101.8380 - mae: 9.3307
Epoch 51/100
1/2 [==============>...............] - ETA: 0s - loss: 99.3541 - mae: 9.22402/2 [==============================] - 0s 2ms/step - loss: 101.8114 - mae: 9.3187
Epoch 52/100
1/2 [==============>...............] - ETA: 0s - loss: 110.6732 - mae: 9.65422/2 [==============================] - 0s 1ms/step - loss: 101.2733 - mae: 9.2713
Epoch 53/100
1/2 [==============>...............] - ETA: 0s - loss: 106.1435 - mae: 9.58262/2 [==============================] - 0s 1ms/step - loss: 98.4434 - mae: 9.2004
Epoch 54/100
1/2 [==============>...............] - ETA: 0s - loss: 89.3724 - mae: 8.78652/2 [==============================] - 0s 1ms/step - loss: 97.0167 - mae: 9.1309
Epoch 55/100
1/2 [==============>...............] - ETA: 0s - loss: 90.7286 - mae: 8.95842/2 [==============================] - 0s 1ms/step - loss: 95.1336 - mae: 9.0838
Epoch 56/100
1/2 [==============>...............] - ETA: 0s - loss: 89.8463 - mae: 8.89392/2 [==============================] - 0s 2ms/step - loss: 95.4673 - mae: 9.0977
Epoch 57/100
1/2 [==============>...............] - ETA: 0s - loss: 98.2422 - mae: 9.26732/2 [==============================] - 0s 1ms/step - loss: 94.6506 - mae: 9.0595
Epoch 58/100
1/2 [==============>...............] - ETA: 0s - loss: 100.5030 - mae: 9.32362/2 [==============================] - 0s 1ms/step - loss: 92.4087 - mae: 8.9473
Epoch 59/100
1/2 [==============>...............] - ETA: 0s - loss: 97.9625 - mae: 9.25152/2 [==============================] - 0s 1ms/step - loss: 93.4377 - mae: 8.9413
Epoch 60/100
1/2 [==============>...............] - ETA: 0s - loss: 89.6973 - mae: 8.86902/2 [==============================] - 0s 1ms/step - loss: 89.7930 - mae: 8.8782
Epoch 61/100
1/2 [==============>...............] - ETA: 0s - loss: 103.3314 - mae: 9.49572/2 [==============================] - 0s 2ms/step - loss: 90.5052 - mae: 8.8499
Epoch 62/100
1/2 [==============>...............] - ETA: 0s - loss: 81.6434 - mae: 8.46522/2 [==============================] - 0s 1ms/step - loss: 88.4325 - mae: 8.8118
Epoch 63/100
1/2 [==============>...............] - ETA: 0s - loss: 81.9218 - mae: 8.55582/2 [==============================] - 0s 1ms/step - loss: 87.1928 - mae: 8.7377
Epoch 64/100
1/2 [==============>...............] - ETA: 0s - loss: 97.8687 - mae: 9.21682/2 [==============================] - 0s 1ms/step - loss: 87.5749 - mae: 8.7207
Epoch 65/100
1/2 [==============>...............] - ETA: 0s - loss: 85.8300 - mae: 8.77962/2 [==============================] - 0s 1ms/step - loss: 84.1327 - mae: 8.6221
Epoch 66/100
1/2 [==============>...............] - ETA: 0s - loss: 86.4823 - mae: 8.72362/2 [==============================] - 0s 1ms/step - loss: 85.0948 - mae: 8.6600
Epoch 67/100
1/2 [==============>...............] - ETA: 0s - loss: 92.5204 - mae: 9.02072/2 [==============================] - 0s 1ms/step - loss: 84.5216 - mae: 8.5666
Epoch 68/100
1/2 [==============>...............] - ETA: 0s - loss: 80.9680 - mae: 8.51552/2 [==============================] - 0s 1ms/step - loss: 80.7480 - mae: 8.4543
Epoch 69/100
1/2 [==============>...............] - ETA: 0s - loss: 82.9867 - mae: 8.57952/2 [==============================] - 0s 1ms/step - loss: 81.5474 - mae: 8.5139
Epoch 70/100
1/2 [==============>...............] - ETA: 0s - loss: 87.5111 - mae: 8.79792/2 [==============================] - 0s 1ms/step - loss: 81.8662 - mae: 8.4381
Epoch 71/100
1/2 [==============>...............] - ETA: 0s - loss: 73.6755 - mae: 8.16892/2 [==============================] - 0s 1ms/step - loss: 78.4304 - mae: 8.3757
Epoch 72/100
1/2 [==============>...............] - ETA: 0s - loss: 74.4608 - mae: 8.16822/2 [==============================] - 0s 1ms/step - loss: 77.8782 - mae: 8.3208
Epoch 73/100
1/2 [==============>...............] - ETA: 0s - loss: 64.3611 - mae: 7.43792/2 [==============================] - 0s 1ms/step - loss: 78.4545 - mae: 8.2083
Epoch 74/100
1/2 [==============>...............] - ETA: 0s - loss: 88.7649 - mae: 8.96182/2 [==============================] - 0s 1ms/step - loss: 76.6388 - mae: 8.2319
Epoch 75/100
1/2 [==============>...............] - ETA: 0s - loss: 73.4171 - mae: 8.01582/2 [==============================] - 0s 1ms/step - loss: 76.3026 - mae: 8.2236
Epoch 76/100
1/2 [==============>...............] - ETA: 0s - loss: 70.5310 - mae: 7.87452/2 [==============================] - 0s 1ms/step - loss: 74.1789 - mae: 8.0802
Epoch 77/100
1/2 [==============>...............] - ETA: 0s - loss: 68.6891 - mae: 7.68632/2 [==============================] - 0s 1ms/step - loss: 73.8013 - mae: 8.0518
Epoch 78/100
1/2 [==============>...............] - ETA: 0s - loss: 61.7765 - mae: 7.33642/2 [==============================] - 0s 1ms/step - loss: 70.7237 - mae: 7.9048
Epoch 79/100
1/2 [==============>...............] - ETA: 0s - loss: 75.8540 - mae: 8.19092/2 [==============================] - 0s 1ms/step - loss: 71.1517 - mae: 7.9357
Epoch 80/100
1/2 [==============>...............] - ETA: 0s - loss: 74.0530 - mae: 7.92882/2 [==============================] - 0s 1ms/step - loss: 70.7982 - mae: 7.8194
Epoch 81/100
1/2 [==============>...............] - ETA: 0s - loss: 65.3336 - mae: 7.57962/2 [==============================] - 0s 1ms/step - loss: 69.0841 - mae: 7.7988
Epoch 82/100
1/2 [==============>...............] - ETA: 0s - loss: 70.6892 - mae: 7.91082/2 [==============================] - 0s 1ms/step - loss: 68.1253 - mae: 7.7398
Epoch 83/100
1/2 [==============>...............] - ETA: 0s - loss: 75.5139 - mae: 8.14532/2 [==============================] - 0s 1ms/step - loss: 68.5250 - mae: 7.7258
Epoch 84/100
1/2 [==============>...............] - ETA: 0s - loss: 65.0316 - mae: 7.54882/2 [==============================] - 0s 1ms/step - loss: 67.5397 - mae: 7.7033
Epoch 85/100
1/2 [==============>...............] - ETA: 0s - loss: 86.0185 - mae: 8.72962/2 [==============================] - 0s 1ms/step - loss: 69.3213 - mae: 7.6848
Epoch 86/100
1/2 [==============>...............] - ETA: 0s - loss: 57.1777 - mae: 7.03852/2 [==============================] - 0s 1ms/step - loss: 66.1668 - mae: 7.5854
Epoch 87/100
1/2 [==============>...............] - ETA: 0s - loss: 67.4651 - mae: 7.74362/2 [==============================] - 0s 1ms/step - loss: 64.1161 - mae: 7.5438
Epoch 88/100
1/2 [==============>...............] - ETA: 0s - loss: 62.6966 - mae: 7.42222/2 [==============================] - 0s 1ms/step - loss: 62.0581 - mae: 7.3678
Epoch 89/100
1/2 [==============>...............] - ETA: 0s - loss: 54.4327 - mae: 6.81762/2 [==============================] - 0s 1ms/step - loss: 62.2358 - mae: 7.3666
Epoch 90/100
1/2 [==============>...............] - ETA: 0s - loss: 59.8742 - mae: 7.29392/2 [==============================] - 0s 1ms/step - loss: 60.8571 - mae: 7.3116
Epoch 91/100
1/2 [==============>...............] - ETA: 0s - loss: 66.4556 - mae: 7.62432/2 [==============================] - 0s 1ms/step - loss: 61.1048 - mae: 7.2636
Epoch 92/100
1/2 [==============>...............] - ETA: 0s - loss: 61.3573 - mae: 7.24372/2 [==============================] - 0s 1ms/step - loss: 60.9226 - mae: 7.2310
Epoch 93/100
1/2 [==============>...............] - ETA: 0s - loss: 61.0086 - mae: 7.31302/2 [==============================] - 0s 1ms/step - loss: 58.4963 - mae: 7.1647
Epoch 94/100
1/2 [==============>...............] - ETA: 0s - loss: 59.6671 - mae: 7.26402/2 [==============================] - 0s 1ms/step - loss: 57.7116 - mae: 7.0850
Epoch 95/100
1/2 [==============>...............] - ETA: 0s - loss: 59.7788 - mae: 7.24162/2 [==============================] - 0s 1ms/step - loss: 56.7107 - mae: 7.0206
Epoch 96/100
1/2 [==============>...............] - ETA: 0s - loss: 60.0962 - mae: 7.24882/2 [==============================] - 0s 1ms/step - loss: 56.1776 - mae: 6.9647
Epoch 97/100
1/2 [==============>...............] - ETA: 0s - loss: 60.5092 - mae: 7.21842/2 [==============================] - 0s 1ms/step - loss: 56.8054 - mae: 7.0018
Epoch 98/100
1/2 [==============>...............] - ETA: 0s - loss: 49.9674 - mae: 6.58552/2 [==============================] - 0s 1ms/step - loss: 53.7946 - mae: 6.8491
Epoch 99/100
1/2 [==============>...............] - ETA: 0s - loss: 47.8377 - mae: 6.43872/2 [==============================] - 0s 1ms/step - loss: 55.1122 - mae: 6.9046
Epoch 100/100
1/2 [==============>...............] - ETA: 0s - loss: 54.9615 - mae: 6.88212/2 [==============================] - 0s 1ms/step - loss: 51.9016 - mae: 6.6497
----------------------------- Captured stderr call -----------------------------
2023-11-27 14:35:01.412565: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz
------------------------------ Captured log call -------------------------------
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[33mWARNING [0m tensorflow:callbacks.py:2052 Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae
[36m[1m=========================== short test summary info ============================[0m
[31mFAILED[0m tests/train_at_scale/test_main_local.py::[1mTestMainLocal::test_route_preprocess_and_train[0m - NameError: name 'data' is not defined
[31mFAILED[0m tests/train_at_scale/test_main_local.py::[1mTestMainLocal::test_route_pred[0m - AttributeError: 'NoneType' object has no attribute 'predict'
[31mFAILED[0m tests/train_at_scale/test_main_local.py::[1mTestMainLocal::test_route_preprocess[0m - ImportError: cannot import name 'preprocess' from 'taxifare.interface.main_...
[31mFAILED[0m tests/train_at_scale/test_main_local.py::[1mTestMainLocal::test_route_train[0m - ImportError: cannot import name 'train' from 'taxifare.interface.main_local...
[31mFAILED[0m tests/train_at_scale/test_model.py::[1mtest_model_can_fit[0m - KeyError: 'val_mae'
[31m================== [31m[1m5 failed[0m, [32m3 passed[0m, [33m103 warnings[0m[31m in 5.48s[0m[31m ===================[0m
